---
title: "Naive Bayes models"
---

```{python import libraries}
# PATH TO CUSTOM MODULES
import sys

sys.path.append("../src")

# IMPORT LIBRARIES
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score
from sklearn.metrics import (
    roc_curve,
    auc,
    roc_auc_score,
    confusion_matrix,
    classification_report,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    precision_recall_curve,
    average_precision_score,
)

import glob
import os

# IMPORT CUSTOM MODULES
import utils.loadDataUtils as ldu
import utils.modelsUtils as mu

from sklearn.naive_bayes import GaussianNB


```


```{python paths, echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE}
# DIRECTORIES
input_path = "../data/processed/"
training_path = input_path + "train_data/"
test_path = input_path + "test_data/"
results_path = "../models/results/"

```

```{python files}
# FILES

# RESULTS FILE
results_file = "results_table.csv"

```

```{python load data}
# GET TRAINING AND TEST CSV FILES
training_csv_files = ldu.get_csv_files(training_path)
test_csv_files = ldu.get_csv_files(test_path)

# GET DATASET NAMES FROM CSV FILES
dataset_names = ldu.get_dataset_names(training_csv_files)

# LOAD TRAINING AND TEST DATA
datasets = ldu.load_training_test_datasets(
    datasets_names=dataset_names, training_path=training_path, test_path=test_path
)

```

# CALCULATE KNN MODEL FOR EACH DATASET

## GLOBAL VARIABLES

```{python knn parameters grid}
nb_var_smoothing = np.logspace(0, -9, num=100)
parameters_grid = dict(
    var_smoothing=nb_var_smoothing,
)
```

## BUILD KNN MODEL

```{python knn model}
nb_model = GaussianNB()
```

```{python calculate knn model}
nb_results = mu.calculate_models(
    model=nb_model,
    parameters_grid=parameters_grid,
    datasets=datasets,
    model_name="Naive_Bayes",
)
```

```{python}
roc_curves = knn_results[1]
knn_results = knn_results[0]
```

```{python save knn results}
# OPEN FILE
file = open(results_path + results_file, "a")
# REMOVE ROWS IN TABLE_RESULTS.CSV THAT STARTS WITH Naive_Bayes
table_results = pd.read_csv(results_path + results_file)
table_results = table_results[
    ~table_results["model_name"].str.startswith("Naive_Bayes")
]
table_results.to_csv(results_path + results_file, index=False)
# WRITE RESULTS
nb_results.to_csv(file, header=False, index=False)
# CLOSE FILE
file.close()
```

# NAIVE BAYES MODEL FOR MACCS KEYS

```{python, echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE}
# BUILD A NAIVE BAYES MODEL FOR MACCS KEYS DATA. USE GRID SEARCH AND CROSS-VALIDATION TO FIND THE BEST HYPERPARAMETERS FOR THE MODEL.
# CREATE A GRID OF POSSIBLE VALUES FOR THE HYPERPARAMETERS

# CREATE THE GRID SEARCH OBJECT
grid_maccs_keys = GridSearchCV(
    estimator=GaussianNB(),
    param_grid=param_grid,
    cv=5,
    n_jobs=-1,
    scoring="roc_auc",
    verbose=1,
)

# FIT THE GRID SEARCH TO THE DATA
grid_maccs_keys.fit(X_training_maccs_keys, Y_training_maccs_keys)

```

```{python}
# WE GET THE BEST KNN MODEL
best_model_maccs_keys = grid_maccs_keys.best_estimator_
best_model_name = "Naive Bayes MACCS Keys"
```

```{python}
# PREDICT
Y_pred_maccs_keys = best_model_maccs_keys.predict(X_test_maccs_keys)
# EVALUATE
accuracy = accuracy_score(Y_test_maccs_keys, Y_pred_maccs_keys)
precision = precision_score(Y_test_maccs_keys, Y_pred_maccs_keys)
recall = recall_score(Y_test_maccs_keys, Y_pred_maccs_keys)
auc_maccs_keys = roc_auc_score(Y_test_maccs_keys, Y_pred_maccs_keys)
# AUC TRAINING
Y_pred_train_maccs_keys = best_model_maccs_keys.predict(X_training_maccs_keys)
auc_train_maccs_keys = roc_auc_score(Y_training_maccs_keys, Y_pred_train_maccs_keys)

# CREATE DATAFRAME WITH RESULTS
results_maccs_keys = pd.DataFrame(
    {
        "model_name": [best_model_name],
        "accuracy": [round(accuracy, 2)],
        "precision": [round(precision, 2)],
        "recall": [round(recall, 2)],
        "auc": [round(auc_maccs_keys, 2)],
        "auc_train": [round(auc_train_maccs_keys, 2)],
    }
)

```

```{python}
# SAVE TABLE_RESULTS.CSV
table_results = pd.read_csv(results_path + results_file)
table_results = table_results.append(results_maccs_keys)
table_results.to_csv(results_path + results_file, index=False)
```

# NAIVE BAYES MODEL FOR ECFP4 FINGERPRINTS

```{python, echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE}
# BUILD A NAIVE BAYES MODEL FOR ECFP4 FINGERPRINTS DATA. USE GRID SEARCH AND CROSS-VALIDATION TO FIND THE BEST HYPERPARAMETERS FOR THE MODEL.
# CREATE A GRID OF POSSIBLE VALUES FOR THE HYPERPARAMETERS
param_grid = {
    "var_smoothing": np.logspace(0, -9, num=100),
}
# CREATE THE GRID SEARCH OBJECT
grid_ecfp4_fingerprints = GridSearchCV(
    estimator=GaussianNB(),
    param_grid=param_grid,
    cv=5,
    n_jobs=-1,
    scoring="roc_auc",
    verbose=1,
)

# FIT THE GRID SEARCH TO THE DATA
grid_ecfp4_fingerprints.fit(
    X_training_ecfp4_fingerprints, Y_training_ecfp4_fingerprints
)

```

```{python}
# WE GET THE BEST KNN MODEL
best_model_ecfp4_fingerprints = grid_ecfp4_fingerprints.best_estimator_
best_model_name = "Naive Bayes ECFP4 Fingerprints"
```

```{python}
# PREDICT
Y_pred_ecfp4_fingerprints = best_model_ecfp4_fingerprints.predict(
    X_test_ecfp4_fingerprints
)
# EVALUATE
accuracy = accuracy_score(Y_test_ecfp4_fingerprints, Y_pred_ecfp4_fingerprints)
precision = precision_score(Y_test_ecfp4_fingerprints, Y_pred_ecfp4_fingerprints)
recall = recall_score(Y_test_ecfp4_fingerprints, Y_pred_ecfp4_fingerprints)
auc_ecfp4_fingerprints = roc_auc_score(
    Y_test_ecfp4_fingerprints, Y_pred_ecfp4_fingerprints
)
# AUC TRAINING
Y_pred_train_ecfp4_fingerprints = best_model_ecfp4_fingerprints.predict(
    X_training_ecfp4_fingerprints
)
auc_train_ecfp4_fingerprints = roc_auc_score(
    Y_training_ecfp4_fingerprints, Y_pred_train_ecfp4_fingerprints
)

# CREATE DATAFRAME WITH RESULTS
results_ecfp4_fingerprints = pd.DataFrame(
    {
        "model_name": [best_model_name],
        "accuracy": [round(accuracy, 2)],
        "precision": [round(precision, 2)],
        "recall": [round(recall, 2)],
        "auc": [round(auc_ecfp4_fingerprints, 2)],
        "auc_train": [round(auc_train_ecfp4_fingerprints, 2)],
    }
)

```

```{python}
# SAVE TABLE_RESULTS.CSV
table_results = pd.read_csv(results_path + results_file)
table_results = table_results.append(results_ecfp4_fingerprints)
table_results.to_csv(results_path + results_file, index=False)
```

# RESULTS FOR NAIVE BAYES MODELS

```{python}
# GET FPR AND TPR FOR ALL MODELS
# MOLECULAR DESCRIPTORS
fpr_molecular_descriptors, tpr_molecular_descriptors, _ = roc_curve(
    Y_test_molecular_descriptors, Y_pred_molecular_descriptors
)
# MACCS KEYS
fpr_maccs_keys, tpr_maccs_keys, _ = roc_curve(Y_test_maccs_keys, Y_pred_maccs_keys)
# ECFP4 FINGERPRINTS
fpr_ecfp4_fingerprints, tpr_ecfp4_fingerprints, _ = roc_curve(
    Y_test_ecfp4_fingerprints, Y_pred_ecfp4_fingerprints
)
```

```{python}
# PLOT ALL THE ROC CURVES IN THE SAME PLOT
plt.figure(figsize=(10, 10))
plt.plot(
    fpr_molecular_descriptors,
    tpr_molecular_descriptors,
    color="red",
    label="Molecular descriptors (AUC = %0.2f)" % auc_molecular_descriptors,
)
plt.plot(
    fpr_maccs_keys,
    tpr_maccs_keys,
    color="green",
    label="MACCS keys (AUC = %0.2f)" % auc_maccs_keys,
)
plt.plot(
    fpr_ecfp4_fingerprints,
    tpr_ecfp4_fingerprints,
    color="blue",
    label="ECFP4 fingerprints (AUC = %0.2f)" % auc_ecfp4_fingerprints,
)
plt.plot([0, 1], [0, 1], color="black", linestyle="--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend(loc="lower right")
plt.savefig(results_path + "knn_roc_curve.png")
plt.show()
```

```{python}
# DROP DUPLICATES FROM TABLE_RESULTS.CSV ACCORDING TO MODEL_NAME
table_results = pd.read_csv(results_path + results_file)
table_results = table_results.drop_duplicates(subset=["model_name"])
table_results.to_csv(results_path + results_file, index=False)
```

