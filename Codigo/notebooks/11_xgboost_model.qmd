---
title: "Random Forest models"
---

```{python import libraries, echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE}
# PATH TO CUSTOM MODULES
import sys

sys.path.append("../src")

# IMPORT LIBRARIES
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score
from sklearn.metrics import (
    roc_curve,
    auc,
    roc_auc_score,
    confusion_matrix,
    classification_report,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    precision_recall_curve,
    average_precision_score,
)

import glob
import os

# IMPORT CUSTOM MODULES
import utils.loadDataUtils as ldu
import utils.modelsUtils as mu
import xgboost as xgb

```

```{python paths, echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE}
# DIRECTORIES
input_path = "../data/processed/"
training_path = input_path + "train_data/"
test_path = input_path + "test_data/"
results_path = "../models/results/"

```

```{python files}
# FILES

# RESULTS FILE
results_file = "results_table.csv"

```

```{python load data}
# GET TRAINING AND TEST CSV FILES
training_csv_files = ldu.get_csv_files(training_path)
test_csv_files = ldu.get_csv_files(test_path)

# GET DATASET NAMES FROM CSV FILES
dataset_names = ldu.get_dataset_names(training_csv_files)

# LOAD TRAINING AND TEST DATA
datasets = ldu.load_training_test_datasets(
    datasets_names=dataset_names, training_path=training_path, test_path=test_path
)

```

# CALCULATE KNN MODEL FOR EACH DATASET

## GLOBAL VARIABLES

```{python knn parameters grid}
xgboost_n_estimators = [1, 10, 50, 100]
xgboost_max_depth = [3, 5, 10]
xgboost_learning_rate = [0.01, 0.1]
xgboost_gamma = [0, 0.1, 0.4]
xgboost_colsample_bytree = [0.3]
xgboost_subsample = [0.3]
xgboost_reg_alpha = [0, 0.1]
xgboost_reg_lambda = [0.1]

parameters_grid = {
    "n_estimators": [10, 50, 100],
    "max_depth": [5, 10, 50],
    "min_samples_split": [5, 10, 20],
    "min_samples_leaf": [5, 10, 50],
    "max_features": ["sqrt", "log2"],
}

```


## BUILD KNN MODEL

```{python knn model}
# IMPORT SVM MODEL
from sklearn import svm
from sklearn.ensemble import RandomForestClassifier

# INSTANTIATE SVM MODEL
svm_model = svm.SVC()
rf_model = RandomForestClassifier(random_state=0)
```


```{python calculate knn model}
xgboost_results = mu.calculate_models(
    model=rf_model,
    parameters_grid=parameters_grid,
    datasets=datasets,
    model_name="XGBoost",
)
```

```{python save knn results}
# OPEN FILE
file = open(results_path + results_file, "a")
# REMOVE ROWS IN TABLE_RESULTS.CSV THAT STARTS WITH XGBoost
table_results = pd.read_csv(results_path + results_file)
table_results = table_results[~table_results["model_name"].str.startswith("XGBoost")]
table_results.to_csv(results_path + results_file, index=False)
# WRITE RESULTS
xgboost_results.to_csv(file, header=False, index=False)
# CLOSE FILE
file.close()
```

# XGBOOST MODEL FOR MACCS KEYS

```{python svm model for maccs keys, echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE}
# BUILD A XGBOOST MODEL FOR MACCS KEYS. USE GRID SEARCH TO EXPLORE ALL THE POSSIBLE COMBINATIONS AND FIND THE BEST PARAMETERS. USE 5-FOLD CROSS VALIDATION.
# DEFINE THE MODEL
xgb_model = xgb.XGBClassifier()

# DEFINE THE GRID SEARCH
grid_maccs_keys = GridSearchCV(
    estimator=xgb_model,
    param_grid=parameters,
    scoring="roc_auc",
    n_jobs=-1,
    cv=5,
    verbose=3,
)
# TRAIN THE MODEL
grid_maccs_keys.fit(X_training_maccs_keys, Y_training_maccs_keys)
```

```{python}
# WE GET THE BEST KNN MODEL
best_model_maccs_keys = grid_maccs_keys.best_estimator_
best_model_name = "XGBOOST MACCS Keys"
```

```{python}
# PREDICT
Y_pred_maccs_keys = best_model_maccs_keys.predict(X_test_maccs_keys)
# EVALUATE
accuracy = accuracy_score(Y_test_maccs_keys, Y_pred_maccs_keys)
precision = precision_score(Y_test_maccs_keys, Y_pred_maccs_keys)
recall = recall_score(Y_test_maccs_keys, Y_pred_maccs_keys)
auc_maccs_keys = roc_auc_score(Y_test_maccs_keys, Y_pred_maccs_keys)
# AUC TRAINING
Y_pred_train_maccs_keys = best_model_maccs_keys.predict(X_training_maccs_keys)
auc_train_maccs_keys = roc_auc_score(Y_training_maccs_keys, Y_pred_train_maccs_keys)

# CREATE DATAFRAME WITH RESULTS
results_maccs_keys = pd.DataFrame(
    {
        "model_name": [best_model_name],
        "accuracy": [round(accuracy, 2)],
        "precision": [round(precision, 2)],
        "recall": [round(recall, 2)],
        "auc": [round(auc_maccs_keys, 2)],
        "auc_train": [round(auc_train_maccs_keys, 2)],
    }
)

```

```{python}
# SAVE TABLE_RESULTS.CSV
table_results = pd.read_csv(results_path + results_file)
table_results = table_results.append(results_maccs_keys)
table_results.to_csv(results_path + results_file, index=False)
```

# XGBOOST MODEL FOR ECFP4

```{python svm model for ecfp4, echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE}
# BUILD A XGBOOST MODEL FOR ECFP4. USE GRID SEARCH TO EXPLORE ALL THE POSSIBLE COMBINATIONS AND FIND THE BEST PARAMETERS. USE 5-FOLD CROSS VALIDATION.
# DEFINE THE MODEL
xgb_model = xgb.XGBClassifier()

# DEFINE THE GRID SEARCH
grid_ecfp4 = GridSearchCV(
    estimator=xgb_model,
    param_grid=parameters,
    scoring="roc_auc",
    n_jobs=-1,
    cv=5,
    verbose=3,
)
# TRAIN THE MODEL
grid_ecfp4.fit(X_training_ecfp4_fingerprints, Y_training_ecfp4_fingerprints)
```

```{python}
# WE GET THE BEST KNN MODEL
best_model_ecfp4 = grid_ecfp4.best_estimator_
best_model_name = "XGBOOST ECFP4"
```

```{python}
# PREDICT
Y_pred_ecfp4_fingerprints = best_model_ecfp4.predict(X_test_ecfp4_fingerprints)
# EVALUATE
accuracy = accuracy_score(Y_test_ecfp4_fingerprints, Y_pred_ecfp4_fingerprints)
precision = precision_score(Y_test_ecfp4_fingerprints, Y_pred_ecfp4_fingerprints)
recall = recall_score(Y_test_ecfp4_fingerprints, Y_pred_ecfp4_fingerprints)
auc_ecfp4_fingerprints = roc_auc_score(
    Y_test_ecfp4_fingerprints, Y_pred_ecfp4_fingerprints
)
# AUC TRAINING
Y_pred_train_ecfp4 = best_model_ecfp4.predict(X_training_ecfp4_fingerprints)
auc_train_ecfp4 = roc_auc_score(Y_training_ecfp4_fingerprints, Y_pred_train_ecfp4)

# CREATE DATAFRAME WITH RESULTS
results_ecfp4 = pd.DataFrame(
    {
        "model_name": [best_model_name],
        "accuracy": [round(accuracy, 2)],
        "precision": [round(precision, 2)],
        "recall": [round(recall, 2)],
        "auc": [round(auc_ecfp4_fingerprints, 2)],
        "auc_train": [round(auc_ecfp4_fingerprints, 2)],
    }
)

```

```{python}
# SAVE TABLE_RESULTS.CSV
table_results = pd.read_csv(results_path + results_file)
table_results = table_results.append(results_ecfp4)
table_results.to_csv(results_path + results_file, index=False)
```

# RESULTS FOR XGBOOST MODELS

```{python}
# GET FPR AND TPR FOR ALL MODELS
# MOLECULAR DESCRIPTORS
fpr_molecular_descriptors, tpr_molecular_descriptors, _ = roc_curve(
    Y_test_molecular_descriptors, Y_pred_molecular_descriptors
)
# MACCS KEYS
fpr_maccs_keys, tpr_maccs_keys, _ = roc_curve(Y_test_maccs_keys, Y_pred_maccs_keys)
# ECFP4 FINGERPRINTS
fpr_ecfp4_fingerprints, tpr_ecfp4_fingerprints, _ = roc_curve(
    Y_test_ecfp4_fingerprints, Y_pred_ecfp4_fingerprints
)
```

```{python}
# PLOT ALL THE ROC CURVES IN THE SAME PLOT
plt.figure(figsize=(10, 10))
plt.plot(
    fpr_molecular_descriptors,
    tpr_molecular_descriptors,
    color="red",
    label="Molecular descriptors (AUC = %0.2f)" % auc_molecular_descriptors,
)
plt.plot(
    fpr_maccs_keys,
    tpr_maccs_keys,
    color="green",
    label="MACCS keys (AUC = %0.2f)" % auc_maccs_keys,
)
plt.plot(
    fpr_ecfp4_fingerprints,
    tpr_ecfp4_fingerprints,
    color="blue",
    label="ECFP4 fingerprints (AUC = %0.2f)" % auc_ecfp4_fingerprints,
)
plt.plot([0, 1], [0, 1], color="black", linestyle="--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend(loc="lower right")
plt.savefig(results_path + "knn_roc_curve.png")
plt.show()
```

```{python}
# DROP DUPLICATES FROM TABLE_RESULTS.CSV ACCORDING TO MODEL_NAME
table_results = pd.read_csv(results_path + results_file)
table_results = table_results.drop_duplicates(subset=["model_name"])
table_results.to_csv(results_path + results_file, index=False)
```







